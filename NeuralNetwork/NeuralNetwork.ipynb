{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as Dataset\n",
    "import torchvision.transforms as Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0426, -0.3446,  0.2274, -0.2598, -0.1002,  0.0891, -0.0981,  0.0544,\n",
      "         -0.1269,  0.4067],\n",
      "        [-0.2905,  0.0494,  0.4223, -0.3073, -0.1803,  0.1236, -0.1611, -0.2429,\n",
      "         -0.0566,  0.4715],\n",
      "        [-0.2657, -0.1046,  0.0569, -0.4400, -0.2916,  0.0652,  0.3386,  0.2083,\n",
      "         -0.3150,  0.4140],\n",
      "        [-0.2457,  0.0339,  0.2699, -0.1339, -0.3600,  0.3843, -0.1498,  0.1070,\n",
      "          0.1391,  0.2254],\n",
      "        [-0.3376,  0.1499,  0.2337, -0.3455, -0.2007,  0.0054,  0.1798,  0.0334,\n",
      "          0.1015,  0.3986],\n",
      "        [-0.2167, -0.0264,  0.1170, -0.2080, -0.0290,  0.0064, -0.1645,  0.0929,\n",
      "         -0.1057,  0.4056],\n",
      "        [-0.2358, -0.1174,  0.3885, -0.1845, -0.1537,  0.4137,  0.0967, -0.1771,\n",
      "         -0.1859,  0.1680],\n",
      "        [-0.4838, -0.2491, -0.0972, -0.2732, -0.1090,  0.0965,  0.2221,  0.1233,\n",
      "         -0.2284,  0.4410],\n",
      "        [-0.1883, -0.0197, -0.1010, -0.2755, -0.2037, -0.0199,  0.1029,  0.1175,\n",
      "         -0.3727,  0.4607],\n",
      "        [-0.1893, -0.0551, -0.1076, -0.3387,  0.0513,  0.4417, -0.1337, -0.0565,\n",
      "         -0.1454,  0.2518],\n",
      "        [-0.3830, -0.2170, -0.1307, -0.3334, -0.4323,  0.1290, -0.0984, -0.0908,\n",
      "         -0.0012,  0.6298],\n",
      "        [-0.1034, -0.1947, -0.0325, -0.2163, -0.5969,  0.2797,  0.0561, -0.2202,\n",
      "         -0.3132,  0.1694],\n",
      "        [ 0.0874, -0.1291,  0.2014, -0.2696, -0.4586,  0.1205,  0.1653,  0.0367,\n",
      "         -0.0906,  0.3222],\n",
      "        [-0.2850, -0.1497, -0.0613, -0.2895, -0.3003, -0.0644, -0.1543, -0.2985,\n",
      "          0.0855,  0.3976],\n",
      "        [-0.4750,  0.0069, -0.1504, -0.1926, -0.4488,  0.0734, -0.0603, -0.0199,\n",
      "          0.0423,  0.3375],\n",
      "        [-0.2611, -0.2503,  0.1505, -0.0731, -0.1193, -0.1797,  0.2434, -0.0826,\n",
      "         -0.0053,  0.6855],\n",
      "        [-0.2178,  0.0313,  0.1168, -0.0457, -0.1781, -0.0109, -0.1831, -0.1495,\n",
      "         -0.1487,  0.2286],\n",
      "        [-0.1149, -0.2586,  0.0159, -0.3012, -0.0571,  0.0067,  0.2582,  0.2799,\n",
      "         -0.3555,  0.7792],\n",
      "        [-0.1124,  0.1566,  0.0259, -0.2432, -0.3419,  0.0163, -0.1859, -0.2020,\n",
      "         -0.0417,  0.6234],\n",
      "        [-0.4121, -0.0721,  0.1135, -0.2739, -0.4137,  0.1241, -0.0668, -0.1710,\n",
      "         -0.4363,  0.3628],\n",
      "        [-0.0810,  0.0684,  0.0079, -0.2261, -0.3670,  0.0294,  0.1296, -0.2511,\n",
      "         -0.3168,  0.3662],\n",
      "        [-0.3430, -0.2432,  0.1043, -0.4023, -0.3558,  0.4743, -0.0118,  0.1616,\n",
      "         -0.5975,  0.3673],\n",
      "        [-0.0526, -0.1949,  0.2369, -0.0240, -0.2993,  0.2928,  0.3314, -0.1290,\n",
      "         -0.2631,  0.5780],\n",
      "        [-0.5339, -0.0261,  0.2018, -0.7070, -0.2069,  0.0292,  0.0959, -0.1197,\n",
      "         -0.2165,  0.8079],\n",
      "        [-0.3744, -0.0917, -0.0217, -0.3023, -0.1724, -0.0567,  0.1507,  0.0169,\n",
      "         -0.1563,  0.4932],\n",
      "        [ 0.3569,  0.0744,  0.4060, -0.2504, -0.3693,  0.2443, -0.3606, -0.0933,\n",
      "         -0.0375,  0.4938],\n",
      "        [-0.0342, -0.1879, -0.0264, -0.2128, -0.3202,  0.2300, -0.2731,  0.2773,\n",
      "         -0.3573,  0.3658],\n",
      "        [-0.3304, -0.2801, -0.1051, -0.2480, -0.4274,  0.1652,  0.7441, -0.2956,\n",
      "         -0.3229,  0.4368],\n",
      "        [-0.2154,  0.1077,  0.1010, -0.0350, -0.3182, -0.3267, -0.0782,  0.0528,\n",
      "         -0.1657,  0.5034],\n",
      "        [-0.2782,  0.2252,  0.1479, -0.2001, -0.3064,  0.3790,  0.3419, -0.2912,\n",
      "         -0.2599,  0.3154],\n",
      "        [-0.1460,  0.0961,  0.3928, -0.1960, -0.3597,  0.6073, -0.1999,  0.1944,\n",
      "          0.1953,  0.5170],\n",
      "        [-0.4554, -0.1194, -0.1935, -0.1601, -0.0105, -0.0374,  0.0076,  0.2550,\n",
      "          0.0964,  0.5234],\n",
      "        [ 0.2956, -0.1780,  0.0204, -0.1948, -0.1817,  0.0626, -0.3982, -0.1624,\n",
      "         -0.1635,  0.8532],\n",
      "        [-0.1076, -0.1676,  0.2754, -0.2354, -0.1532,  0.3359,  0.0789,  0.0139,\n",
      "          0.1025,  0.1739],\n",
      "        [-0.6085,  0.2031,  0.0321, -0.1944, -0.1308, -0.0597, -0.2066, -0.3239,\n",
      "          0.0371,  0.1129],\n",
      "        [-0.0706,  0.1069,  0.2822, -0.3175, -0.7886,  0.3258, -0.0550, -0.4014,\n",
      "         -0.2314,  0.7931],\n",
      "        [ 0.0249, -0.3481, -0.1669,  0.0265, -0.6909,  0.0438,  0.0547,  0.0991,\n",
      "         -0.1604,  0.3230],\n",
      "        [-0.3452, -0.1902, -0.0172, -0.0411, -0.2421, -0.0081,  0.0531,  0.0731,\n",
      "         -0.1358,  0.0202],\n",
      "        [-0.0144, -0.2570,  0.1644, -0.2386, -0.3733, -0.1021, -0.2045,  0.0962,\n",
      "          0.1180,  0.6623],\n",
      "        [-0.5575,  0.2636, -0.3917, -0.0563, -0.3439,  0.0208,  0.0816, -0.2557,\n",
      "          0.1160,  0.1047],\n",
      "        [-0.3331,  0.2096,  0.1169, -0.1905, -0.4648,  0.3015,  0.1621, -0.0329,\n",
      "         -0.4139,  0.1859],\n",
      "        [-0.7194, -0.0849,  0.0669, -0.3225, -0.0717,  0.2433,  0.1049,  0.1391,\n",
      "         -0.2115,  0.3118],\n",
      "        [-0.1108,  0.0304, -0.0037, -0.2006, -0.1110,  0.1800, -0.2504, -0.0268,\n",
      "         -0.0748,  0.1631],\n",
      "        [-0.1431,  0.2279,  0.2734, -0.0941, -0.6408,  0.1984,  0.4360, -0.1289,\n",
      "          0.0917,  0.5010],\n",
      "        [-0.4184, -0.2512,  0.0815, -0.4673, -0.1588,  0.2184, -0.0279,  0.0740,\n",
      "          0.0967,  0.4828],\n",
      "        [ 0.0663, -0.3214,  0.3289, -0.4900, -0.2539,  0.0819, -0.5562,  0.0368,\n",
      "          0.0109,  0.6552],\n",
      "        [-0.3850,  0.0425,  0.2991, -0.2461, -0.1029,  0.2547, -0.2619,  0.0657,\n",
      "          0.0229,  0.5993],\n",
      "        [-0.3797,  0.0163,  0.1528, -0.3214, -0.0913, -0.0914, -0.0691, -0.2081,\n",
      "         -0.1844,  0.3978],\n",
      "        [-0.3467, -0.3523,  0.0255, -0.4111,  0.0451,  0.0404, -0.0997, -0.1763,\n",
      "          0.0629,  0.4297],\n",
      "        [-0.1376,  0.2531, -0.0259, -0.1685, -0.4552,  0.3696, -0.4894, -0.0733,\n",
      "         -0.0156,  0.9176],\n",
      "        [-0.1663, -0.4906,  0.4107,  0.1270, -0.0984, -0.1304,  0.2992, -0.1204,\n",
      "         -0.1595,  0.2822],\n",
      "        [-0.0414, -0.0630,  0.0032, -0.1113, -0.2214,  0.1946,  0.2477,  0.0268,\n",
      "         -0.0427,  0.5253],\n",
      "        [ 0.0459, -0.2759, -0.2194, -0.2536, -0.3520, -0.4281, -0.1786,  0.0289,\n",
      "          0.1810,  0.3657],\n",
      "        [-0.1887,  0.0658,  0.2878, -0.1095, -0.3189, -0.0929, -0.0718, -0.3450,\n",
      "         -0.1939,  0.4961],\n",
      "        [ 0.0980,  0.2192,  0.6530, -0.1629, -0.5332,  0.1691, -0.1490, -0.0113,\n",
      "         -0.0221,  0.5629],\n",
      "        [-0.3954,  0.1193,  0.1398, -0.2013, -0.0958,  0.2393, -0.1402,  0.1276,\n",
      "          0.0245,  0.5124],\n",
      "        [-0.2409,  0.1157, -0.0927, -0.0782, -0.2455,  0.2583, -0.3758, -0.1746,\n",
      "         -0.1843,  0.3291],\n",
      "        [-0.0634, -0.0050,  0.1227,  0.0605, -0.1771,  0.1624, -0.0991,  0.3453,\n",
      "          0.2271,  0.5654],\n",
      "        [-0.0950, -0.0568,  0.1736, -0.0552,  0.0215, -0.1342, -0.3560,  0.1738,\n",
      "         -0.1555,  0.6990],\n",
      "        [ 0.0785, -0.0616,  0.0488, -0.3997, -0.2922,  0.3483,  0.1340, -0.1621,\n",
      "         -0.3594,  0.2936],\n",
      "        [-0.2827, -0.0389,  0.0353, -0.2194, -0.4258, -0.1465, -0.3050, -0.1729,\n",
      "          0.0185,  0.6158],\n",
      "        [-0.3579, -0.2951, -0.1787, -0.4568,  0.1046,  0.0419,  0.0959,  0.0565,\n",
      "         -0.3055,  0.4931],\n",
      "        [ 0.0285, -0.2910,  0.2091, -0.3072, -0.3489, -0.2879,  0.1543, -0.0583,\n",
      "         -0.0658,  0.8309],\n",
      "        [-0.0360,  0.1235, -0.2676, -0.3612, -0.3916,  0.0141, -0.2164, -0.2083,\n",
      "         -0.1178,  0.3165]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(784,50,10)\n",
    "x = torch.randn(64, 784)\n",
    "print(model.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_SIZE = 784\n",
    "NUM_CLASSES = 10\n",
    "HIDDEN_SIZE = 50\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:04<00:00, 2147064.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2045209.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2119703.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 671005.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "'''\n",
    "Transform the data from numpy arrays to tensor and save it in data folder\n",
    "'''\n",
    "train_dataset = Dataset.MNIST(root=\"data/\", train=True,download=True, transform=Transforms.ToTensor()) \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# test set\n",
    "test_dataset = Dataset.MNIST(root=\"data/\", train=False, download=True, transform=Transforms.ToTensor()) \n",
    "testloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([0, 2, 8, 3, 7, 2, 2, 0, 1, 3, 0, 9, 0, 3, 5, 9, 9, 0, 3, 8, 4, 4, 9, 7,\n",
      "        3, 6, 4, 1, 5, 7, 2, 3, 7, 3, 9, 8, 2, 7, 5, 3, 9, 5, 6, 9, 8, 7, 2, 9,\n",
      "        2, 9, 0, 2, 7, 2, 5, 4, 5, 3, 6, 4, 4, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for id, (data, target), in enumerate(train_loader):\n",
    "    print(id)\n",
    "    print(target)\n",
    "    break\n",
    "    print(\"----=-=-=-\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init network\n",
    "model = NeuralNet(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_classes=NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "crossEntropy = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch ==> 1\n",
      "Loss -> 0.44054874777793884\n",
      "=============================\n",
      "\n",
      "epoch ==> 2\n",
      "Loss -> 0.164377823472023\n",
      "=============================\n",
      "\n",
      "epoch ==> 3\n",
      "Loss -> 0.05167372524738312\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'\\nepoch ==> {epoch+1}')\n",
    "    loss = float('-inf')\n",
    "    for id, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        data = data.reshape(data.shape[0], -1) # makes each batch dimention form [64, 1,28, 28] to [64, 784]\n",
    "        \n",
    "        # forward pass\n",
    "        score = model.forward(data)\n",
    "        loss = crossEntropy(score,targets)\n",
    "        # print(f'score - {loss}')\n",
    "\n",
    "        # backpass\n",
    "        optimizer.zero_grad() # set each gradient to 0 initially\n",
    "        loss.backward()\n",
    "\n",
    "        # optimization or gradient decent\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Loss -> {loss}\")\n",
    "    print(\"=============================\")\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on test and test\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Accuracy on train data\")\n",
    "    else:\n",
    "        print(\"Accuracy on test data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_sample = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            score = model.forward(x)\n",
    "            _, predictions = score.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_sample += predictions.size(0)\n",
    "        print(f'accuracy : {float(num_correct)/float(num_sample)}')\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data\n",
      "accuracy : 0.9600166666666666\n",
      "Accuracy on test data\n",
      "accuracy : 0.9552\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader, model)\n",
    "check_accuracy(testloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
