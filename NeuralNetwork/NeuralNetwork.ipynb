{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as Dataset\n",
    "import torchvision.transforms as Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size1,hidden_size2, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.0729e-02,  1.9028e-01, -1.2966e-01,  1.4531e-01,  5.1238e-02,\n",
      "          1.5413e-01, -1.4303e-01,  1.4381e-01, -9.3080e-02, -1.4391e-01],\n",
      "        [-2.0356e-02,  5.3236e-02, -2.1384e-02,  3.2317e-02,  2.7859e-02,\n",
      "         -2.6877e-02, -1.6977e-01,  2.0572e-01,  8.9520e-03, -9.0600e-02],\n",
      "        [ 8.1504e-02,  6.7948e-02, -6.6629e-02,  5.8014e-02,  6.2482e-02,\n",
      "         -6.4132e-02, -1.5354e-01,  1.0369e-01, -1.3964e-02, -1.4155e-01],\n",
      "        [ 4.1267e-02,  4.1639e-03, -2.5967e-02,  5.1997e-02,  8.1266e-02,\n",
      "          2.7078e-02, -2.3101e-01,  9.8578e-02, -1.9938e-01, -5.0028e-02],\n",
      "        [-5.9154e-02,  1.5944e-01,  1.3113e-01,  5.8829e-02,  1.1611e-01,\n",
      "          5.5537e-02, -1.1702e-01,  8.8423e-02, -1.5074e-01, -2.0937e-02],\n",
      "        [-2.1731e-02,  1.4816e-01,  2.9013e-02,  1.4533e-01,  1.1534e-01,\n",
      "          7.0762e-02, -1.7427e-01,  9.6455e-02,  1.4628e-02, -1.2738e-01],\n",
      "        [-1.3967e-02,  1.4416e-01, -2.3666e-02,  2.8941e-02,  2.1658e-03,\n",
      "          2.6234e-02, -2.1674e-01,  1.5153e-01,  1.2323e-02, -6.2597e-02],\n",
      "        [-1.1358e-01,  1.0607e-01,  4.6342e-02,  1.1168e-01,  5.1672e-02,\n",
      "         -3.0769e-02, -1.1157e-01,  1.6709e-01, -9.3696e-02, -1.0544e-01],\n",
      "        [-6.2827e-02,  2.8277e-01,  9.3986e-02, -1.8376e-03,  4.5296e-02,\n",
      "          5.6751e-02,  6.1685e-03,  2.4848e-01, -2.0905e-02, -9.4032e-02],\n",
      "        [-8.8935e-02,  1.2613e-01, -8.4209e-02,  2.8957e-02,  5.7122e-03,\n",
      "          2.8837e-02, -4.6540e-02,  2.1014e-01, -1.3000e-01, -1.4751e-01],\n",
      "        [-3.2315e-02,  1.4732e-01,  3.4136e-02,  9.5155e-02,  7.6015e-02,\n",
      "          1.6037e-02, -6.2475e-02,  1.4033e-01, -4.2616e-02,  1.3514e-03],\n",
      "        [-6.9210e-02,  2.5609e-01, -9.8225e-02,  2.0521e-01,  1.7001e-01,\n",
      "          4.3965e-02, -9.7179e-02,  2.7477e-01,  3.4290e-02, -1.6545e-01],\n",
      "        [ 9.4541e-02,  1.6773e-01, -4.7580e-02,  1.5650e-01, -4.6101e-03,\n",
      "         -8.9044e-02, -1.5930e-01,  1.0930e-01,  4.3721e-04, -5.3655e-02],\n",
      "        [-4.8223e-03,  1.2154e-01, -2.6936e-02,  4.8679e-02,  1.2899e-01,\n",
      "          1.0274e-02, -1.7924e-01,  1.0491e-01,  8.9320e-02, -1.6982e-01],\n",
      "        [-8.2369e-02,  1.6131e-01, -3.9250e-02,  1.6912e-01,  1.1990e-01,\n",
      "         -5.0316e-02, -1.6732e-01,  1.0971e-01,  2.1253e-02, -9.9120e-02],\n",
      "        [-5.3107e-03,  2.6922e-01, -4.9935e-02,  7.9870e-02,  4.1172e-02,\n",
      "          2.8011e-02, -1.9103e-01,  7.6338e-02,  9.6101e-02, -2.2364e-01],\n",
      "        [ 3.6618e-02,  1.7284e-01,  7.6410e-02, -5.8077e-02,  1.2000e-01,\n",
      "         -3.2658e-02, -1.6877e-01,  2.4354e-01,  5.2763e-02, -1.8117e-01],\n",
      "        [ 5.5346e-02,  1.1524e-01, -1.1952e-01,  1.2750e-01, -1.2072e-01,\n",
      "         -8.4130e-02, -1.7591e-01,  2.3516e-01,  5.2270e-02,  5.2593e-02],\n",
      "        [-8.4626e-02,  1.0128e-01, -6.7378e-02,  1.1660e-01,  8.3519e-03,\n",
      "          1.0114e-02,  1.1738e-03,  5.7806e-02, -8.9953e-02, -5.9043e-02],\n",
      "        [-9.2758e-02,  3.8738e-01, -1.4420e-02,  2.0355e-01,  9.1285e-02,\n",
      "          1.3420e-01, -1.3436e-01,  1.0183e-02,  9.5194e-02, -1.7812e-01],\n",
      "        [ 9.1502e-02, -2.6559e-02, -2.0952e-02,  6.1539e-02,  6.4915e-02,\n",
      "         -2.9109e-02, -1.4841e-01,  1.5884e-01,  7.6510e-02, -1.8510e-01],\n",
      "        [-3.6734e-02,  3.0895e-01, -4.0617e-02,  1.1512e-01,  7.2599e-02,\n",
      "          3.2694e-02, -9.0221e-02,  2.9550e-01, -8.7517e-02, -6.9447e-02],\n",
      "        [-3.0465e-02,  2.2229e-01, -4.8066e-02,  8.6520e-02,  3.4828e-02,\n",
      "         -4.2599e-02, -1.0917e-01,  7.6334e-02, -1.6257e-01, -3.0324e-02],\n",
      "        [-2.6268e-02,  1.8156e-01, -5.4159e-02,  7.9186e-02,  1.2470e-02,\n",
      "          1.2188e-01, -1.0113e-01,  2.7371e-01, -9.7153e-02, -1.6448e-01],\n",
      "        [ 9.0012e-02,  4.8939e-02, -2.5879e-03,  1.5868e-02,  1.9221e-02,\n",
      "         -8.9316e-02, -7.4307e-02,  8.8112e-02, -1.5117e-02, -4.2334e-02],\n",
      "        [ 9.2599e-02,  2.1528e-01, -6.1646e-02,  7.5711e-02,  5.0403e-02,\n",
      "         -1.6287e-01, -2.0968e-01,  2.2741e-01,  3.6819e-02, -6.0367e-02],\n",
      "        [ 1.0012e-02,  3.8046e-01, -9.0126e-02,  1.3008e-01,  2.4944e-02,\n",
      "         -9.4703e-03, -7.7227e-02,  3.1874e-01,  4.0130e-02, -1.7016e-01],\n",
      "        [-4.2951e-02,  2.0180e-01,  3.6839e-02,  6.4853e-03,  8.1819e-02,\n",
      "          7.1486e-02, -1.4493e-01,  2.4305e-01, -1.9559e-01,  4.9802e-02],\n",
      "        [ 2.1637e-02,  1.9513e-01, -4.2096e-02,  1.4341e-01,  4.8206e-02,\n",
      "          1.9747e-02, -9.1667e-02,  4.5225e-05,  1.7405e-02, -1.1431e-01],\n",
      "        [-5.6874e-02,  3.2638e-01, -9.7103e-02,  1.5590e-01,  2.3352e-01,\n",
      "          3.1479e-02, -5.0861e-02,  2.0980e-01, -1.5402e-01, -1.3129e-01],\n",
      "        [ 8.5143e-03,  1.6851e-01, -6.8245e-02,  1.3575e-01,  1.9898e-02,\n",
      "         -8.2730e-02, -1.4379e-01,  8.7269e-02, -9.3755e-02, -3.8833e-02],\n",
      "        [ 5.5206e-02,  1.6007e-01, -2.7293e-02,  2.6865e-01,  7.9956e-02,\n",
      "          1.0762e-01, -8.3248e-02,  1.8768e-01, -5.7437e-02, -5.0028e-02],\n",
      "        [ 3.4659e-02,  1.8158e-01, -5.0239e-02,  1.9386e-01,  1.7816e-01,\n",
      "          3.0830e-02, -7.1835e-02,  1.1923e-01, -1.2046e-01, -4.3963e-02],\n",
      "        [-6.2256e-02,  6.3325e-02, -1.6152e-02,  5.7282e-02,  1.4196e-01,\n",
      "         -5.2065e-02, -1.0580e-01,  1.2415e-01,  2.2881e-02, -1.5350e-01],\n",
      "        [-7.9729e-02,  1.5285e-01, -6.7477e-02,  5.3095e-02,  1.0960e-01,\n",
      "          2.9330e-02, -1.9241e-01,  2.5170e-01,  1.5004e-01, -1.2935e-01],\n",
      "        [-4.8183e-02,  1.2611e-01, -1.0245e-02,  1.7231e-01,  1.7007e-02,\n",
      "         -3.0602e-02, -3.6930e-02,  1.1986e-01, -6.9300e-02, -4.2055e-02],\n",
      "        [ 3.6122e-02,  1.1554e-01, -4.6218e-02, -4.1459e-02,  8.1595e-02,\n",
      "         -2.1052e-02, -1.9007e-01,  2.3127e-01,  4.8204e-04, -1.0021e-01],\n",
      "        [-1.0707e-01,  1.5670e-01,  4.4663e-02,  1.5839e-01,  5.1791e-02,\n",
      "          2.5843e-02, -1.0674e-01,  1.1228e-01, -1.0181e-01, -1.0299e-01],\n",
      "        [ 4.3849e-02,  2.1754e-01,  1.2418e-02,  1.3834e-02,  1.6152e-01,\n",
      "         -2.1735e-02, -1.1926e-01,  1.4532e-01,  4.7177e-02, -1.0524e-01],\n",
      "        [ 5.2236e-02,  8.4936e-02,  3.1204e-02,  1.1677e-01,  7.2970e-03,\n",
      "         -5.3676e-02, -1.2547e-01,  1.1542e-01, -2.9476e-02, -8.9398e-02],\n",
      "        [-8.6073e-02,  2.2117e-01, -3.3273e-02,  1.4739e-01,  8.4703e-02,\n",
      "          8.6354e-02, -1.8544e-01,  2.1351e-01, -2.4553e-02, -1.3710e-01],\n",
      "        [-9.9118e-02,  5.0976e-02, -1.1824e-02,  9.4324e-02,  1.1318e-01,\n",
      "         -3.0318e-02, -2.7296e-02,  6.5102e-02, -4.4463e-02, -5.9535e-02],\n",
      "        [ 6.6724e-02,  1.7542e-01, -1.5426e-02,  1.2288e-01,  1.2576e-01,\n",
      "          1.4899e-02, -1.1970e-01,  1.9226e-01, -1.7479e-02, -5.8095e-02],\n",
      "        [ 5.3013e-02,  1.4089e-01, -8.9961e-02,  1.9935e-01,  3.3254e-03,\n",
      "          8.5855e-02, -1.4892e-01,  4.6548e-02, -7.5749e-03, -1.8761e-01],\n",
      "        [-4.4606e-02,  1.6049e-01, -2.9931e-02,  1.8701e-01,  9.6249e-02,\n",
      "          1.0193e-01, -1.2385e-01,  1.0523e-01, -2.8329e-02, -1.9681e-01],\n",
      "        [ 1.9366e-02,  2.2601e-01, -1.9503e-02,  1.0161e-01,  1.1887e-01,\n",
      "          6.0046e-03, -1.4964e-01,  1.7248e-01,  7.1916e-02, -1.2065e-01],\n",
      "        [ 3.4846e-03,  1.5692e-01,  4.8854e-02,  9.6600e-02,  9.8576e-02,\n",
      "          5.9193e-02, -4.5567e-02,  8.8541e-02, -1.2672e-01, -4.7518e-02],\n",
      "        [ 2.7597e-02,  9.1459e-02,  3.2565e-02, -6.8104e-02,  1.4758e-02,\n",
      "          3.4127e-02, -1.9653e-01,  3.0693e-01, -6.5385e-03, -3.8152e-02],\n",
      "        [-3.7682e-02,  3.0621e-01,  1.1926e-01,  3.5178e-02,  1.9647e-01,\n",
      "          8.7222e-02, -1.0631e-01,  1.6380e-01, -1.6330e-01, -7.9907e-02],\n",
      "        [-1.1024e-01,  1.4743e-01,  7.4597e-03,  4.8799e-02,  2.1999e-02,\n",
      "         -8.0630e-02, -7.1224e-02,  1.1014e-01, -6.2690e-03, -9.3311e-02],\n",
      "        [-6.4250e-02,  2.1222e-01, -1.0299e-02,  1.1649e-01,  1.6049e-01,\n",
      "          8.6600e-02, -1.5154e-01,  2.1120e-01, -1.2347e-01, -3.9108e-02],\n",
      "        [ 1.1314e-01,  9.8544e-02, -2.2350e-02,  9.3869e-02,  3.6316e-02,\n",
      "         -8.2888e-02, -2.2570e-01,  7.9409e-02,  2.6207e-02, -1.6114e-02],\n",
      "        [-4.9017e-03,  8.4426e-02, -1.2165e-01,  2.9377e-02, -2.0138e-02,\n",
      "         -9.0453e-02, -1.4534e-01,  1.2534e-01, -2.0247e-01,  2.7716e-02],\n",
      "        [-9.8840e-04,  1.1477e-01, -2.3429e-02,  3.4870e-03,  1.1790e-01,\n",
      "         -1.6598e-02, -6.4864e-02,  1.7411e-01, -4.3236e-02, -7.7552e-02],\n",
      "        [ 1.4079e-02,  1.5624e-01, -1.0655e-01,  1.1477e-01,  1.5318e-01,\n",
      "         -4.7894e-02, -1.9940e-01,  1.7404e-01, -8.9760e-02, -1.3367e-01],\n",
      "        [ 1.2107e-01,  9.3561e-02,  8.1939e-02, -4.4196e-02, -1.5443e-02,\n",
      "         -3.2824e-01, -1.4644e-01,  1.7535e-01,  6.9425e-02,  6.1561e-02],\n",
      "        [-2.4640e-02,  1.6938e-01,  8.0099e-04,  1.5396e-02,  9.9632e-02,\n",
      "          2.8797e-02, -1.9297e-01,  1.3420e-01, -9.6961e-02, -5.5297e-02],\n",
      "        [-1.0093e-01,  1.6284e-01, -1.7385e-02,  2.4772e-02, -1.9636e-03,\n",
      "         -6.5673e-02, -1.4662e-01,  2.1646e-01,  1.2505e-01, -1.4876e-01],\n",
      "        [-3.6908e-02,  3.0469e-01, -1.4558e-03,  1.2979e-01,  1.4960e-01,\n",
      "         -1.2631e-02, -1.1710e-01,  1.9333e-01,  2.8912e-02, -1.6292e-01],\n",
      "        [ 1.2076e-01,  1.5596e-01, -1.9570e-02,  4.7634e-02,  1.1852e-01,\n",
      "         -1.2505e-01, -2.2808e-02,  2.2293e-01,  4.1209e-02, -1.0488e-01],\n",
      "        [-6.3250e-02,  1.9530e-01,  7.5790e-03,  1.2077e-01,  1.2261e-01,\n",
      "         -1.1170e-01, -1.4981e-01,  1.7088e-01, -9.3531e-02, -8.9780e-03],\n",
      "        [-2.1198e-02,  8.2251e-02, -7.1340e-02, -9.7638e-04,  1.8421e-01,\n",
      "         -1.5344e-02, -1.1958e-01,  2.8455e-01, -6.5669e-02, -1.1601e-01],\n",
      "        [ 4.7021e-03,  1.0153e-01,  3.4056e-02,  7.1646e-02,  9.8433e-02,\n",
      "         -1.6603e-01, -1.9450e-01,  1.7616e-01,  6.3013e-02, -5.1641e-02],\n",
      "        [-2.5694e-02,  9.7161e-02,  5.8382e-02,  5.4404e-02,  8.8993e-02,\n",
      "         -4.7348e-02, -1.2192e-01,  1.3856e-01, -9.5789e-02, -3.5641e-02]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(784,225,50,10)\n",
    "x = torch.randn(64, 784)\n",
    "print(model.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_SIZE = 784\n",
    "NUM_CLASSES = 10\n",
    "HIDDEN_SIZE1 = 225\n",
    "HIDDEN_SIZE2 = 50\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "'''\n",
    "Transform the data from numpy arrays to tensor and save it in data folder\n",
    "'''\n",
    "train_dataset = Dataset.MNIST(root=\"data/\", train=True,download=True, transform=Transforms.ToTensor()) \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# test set\n",
    "test_dataset = Dataset.MNIST(root=\"data/\", train=False, download=True, transform=Transforms.ToTensor()) \n",
    "testloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([0, 2, 8, 3, 7, 2, 2, 0, 1, 3, 0, 9, 0, 3, 5, 9, 9, 0, 3, 8, 4, 4, 9, 7,\n",
      "        3, 6, 4, 1, 5, 7, 2, 3, 7, 3, 9, 8, 2, 7, 5, 3, 9, 5, 6, 9, 8, 7, 2, 9,\n",
      "        2, 9, 0, 2, 7, 2, 5, 4, 5, 3, 6, 4, 4, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for id, (data, target), in enumerate(train_loader):\n",
    "    print(id)\n",
    "    print(target)\n",
    "    break\n",
    "    print(\"----=-=-=-\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# init network\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m NeuralNet(input_size\u001b[39m=\u001b[39;49mINPUT_SIZE, hidden_size1\u001b[39m=\u001b[39;49mHIDDEN_SIZE1, hidden_size2\u001b[39m=\u001b[39;49mHIDDEN_SIZE2, num_classes\u001b[39m=\u001b[39;49mNUM_CLASSES)\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# init network\n",
    "model = NeuralNet(input_size=INPUT_SIZE, hidden_size1=HIDDEN_SIZE1, hidden_size2=HIDDEN_SIZE2, num_classes=NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "crossEntropy = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch ==> 1\n",
      "Loss -> 0.00012198904732940719\n",
      "=============================\n",
      "\n",
      "epoch ==> 2\n",
      "Loss -> 4.546681520878337e-05\n",
      "=============================\n",
      "\n",
      "epoch ==> 3\n",
      "Loss -> 3.85180173907429e-05\n",
      "=============================\n",
      "\n",
      "epoch ==> 4\n",
      "Loss -> 0.00015153099957387894\n",
      "=============================\n",
      "\n",
      "epoch ==> 5\n",
      "Loss -> 0.0001348896330455318\n",
      "=============================\n",
      "\n",
      "epoch ==> 6\n",
      "Loss -> 8.355016689165495e-06\n",
      "=============================\n",
      "\n",
      "epoch ==> 7\n",
      "Loss -> 3.65123305527959e-05\n",
      "=============================\n",
      "\n",
      "epoch ==> 8\n",
      "Loss -> 4.283939233573619e-06\n",
      "=============================\n",
      "\n",
      "epoch ==> 9\n",
      "Loss -> 7.487773245884455e-07\n",
      "=============================\n",
      "\n",
      "epoch ==> 10\n",
      "Loss -> 0.0005914241191931069\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "epoch_loss = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'\\nepoch ==> {epoch+1}')\n",
    "    loss = float('-inf')\n",
    "    for id, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        data = data.reshape(data.shape[0], -1) # makes each batch dimention form [64, 1,28, 28] to [64, 784]\n",
    "        \n",
    "        # forward pass\n",
    "        score = model.forward(data)\n",
    "        loss = crossEntropy(score,targets)\n",
    "        # print(f'score - {loss}')\n",
    "\n",
    "        # backpass\n",
    "        optimizer.zero_grad() # set each gradient to 0 initially\n",
    "        loss.backward()\n",
    "\n",
    "        # optimization or gradient decent\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss.append(loss)\n",
    "    print(f\"Loss -> {loss}\")\n",
    "    print(\"=============================\")\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on test and test\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Accuracy on train data\")\n",
    "    else:\n",
    "        print(\"Accuracy on test data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_sample = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            score = model.forward(x)\n",
    "            _, predictions = score.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_sample += predictions.size(0)\n",
    "        print(f'accuracy : {float(num_correct)/float(num_sample)}')\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data\n",
      "accuracy : 0.9992333333333333\n",
      "Accuracy on test data\n",
      "accuracy : 0.9812\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader, model)\n",
    "check_accuracy(testloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
